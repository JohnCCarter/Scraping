#!/usr/bin/env python3
"""
ü§ñ AI DASHBOARD - INTELLIGENT SCRAPING & SMART ANALYTICS
Steg C: AI-driven features, auto-selectors, intelligent insights
"""

import asyncio
import time
import threading
import random
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from enum import Enum
import aiohttp
from bs4 import BeautifulSoup
import numpy as np

# Importera v√•ra moduler
from src.dashboard.app import DashboardApp
from src.utils.config import Config
from src.utils.logging import ScrapingLogger
from src.scraper.ai_intelligence import AIIntelligenceOrchestrator


class AIScrapingMode(Enum):
    """AI scraping modes"""

    AUTO = "auto"
    SEMI_AUTO = "semi_auto"
    MANUAL = "manual"
    LEARNING = "learning"


class IntelligentScraper:
    """AI-powered scraper med intelligent features"""

    def __init__(self):
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        self.start_time = time.time()
        self.session = None
        self.is_running = False

        # AI Components
        self.ai_orchestrator = AIIntelligenceOrchestrator()
        self.ai_mode = AIScrapingMode.AUTO
        self.learning_data = []
        self.auto_selectors = {}
        self.intelligent_insights = []

        # AI Metrics
        self.ai_success_rate = 0.0
        self.selector_accuracy = 0.0
        self.learning_progress = 0.0
        self.ai_recommendations = []

        # Smart Analytics
        self.pattern_recognition = {}
        self.anomaly_detection = []
        self.predictive_analytics = {}
        self.content_analysis = {}

    async def start(self):
        """Startar AI scraper"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=10),
            headers={"User-Agent": "IntelligentScraper/1.0"},
        )
        self.is_running = True

        # AI components √§r redan initierade

    async def stop(self):
        """Stoppar AI scraper"""
        if self.session:
            await self.session.close()
        self.is_running = False

    async def scrape_with_ai(self, url: str, target_data: str = None) -> Dict[str, Any]:
        """Scrapar med AI-assistans"""
        if not self.is_running:
            return {"url": url, "error": "Scraper is not running", "status": "error"}

        start_time = time.time()

        try:
            async with self.session.get(url) as response:
                content = await response.text()
                response_time = time.time() - start_time

                # AI-powered content analysis
                ai_analysis = await self._analyze_content_with_ai(content, url, target_data)

                # Uppdatera metrics
                self._update_ai_metrics(response.status, response_time, ai_analysis)

                return {
                    "url": url,
                    "status": response.status,
                    "response_time": response_time,
                    "ai_analysis": ai_analysis,
                    "content_length": len(content),
                    "ai_mode": self.ai_mode.value,
                }

        except Exception as e:
            self.request_count += 1
            self.error_count += 1
            return {"url": url, "error": str(e), "status": "error"}

    async def _analyze_content_with_ai(self, content: str, url: str, target_data: str = None) -> Dict[str, Any]:
        """Analyserar inneh√•ll med AI"""
        analysis = {
            "selectors_generated": [],
            "content_insights": {},
            "recommendations": [],
            "confidence_score": 0.0,
        }

        try:
            # Generera selectors automatiskt
            if target_data:
                try:
                    selectors = await self.ai_orchestrator.generate_selectors(url, target_data)
                    analysis["selectors_generated"] = selectors
                except Exception as e:
                    analysis["selectors_generated"] = {"error": str(e)}

            # Analysera inneh√•ll
            soup = BeautifulSoup(content, "html.parser")

            # AI content analysis
            analysis["content_insights"] = {
                "title": (soup.find("title").get_text() if soup.find("title") else "No title"),
                "headings": [h.get_text() for h in soup.find_all(["h1", "h2", "h3"])],
                "links_count": len(soup.find_all("a")),
                "images_count": len(soup.find_all("img")),
                "text_length": len(soup.get_text()),
                "structure_score": self._calculate_structure_score(soup),
            }

            # AI recommendations
            analysis["recommendations"] = await self._generate_ai_recommendations(soup, url)

            # Confidence score
            analysis["confidence_score"] = self._calculate_confidence_score(analysis)

        except Exception as e:
            analysis["error"] = str(e)

        return analysis

    def _calculate_structure_score(self, soup) -> float:
        """Ber√§knar struktur-score f√∂r sidan"""
        score = 0.0

        # Kolla efter vanliga element
        if soup.find("title"):
            score += 0.2
        if soup.find("h1"):
            score += 0.2
        if soup.find("nav"):
            score += 0.1
        if soup.find("main"):
            score += 0.1
        if soup.find("footer"):
            score += 0.1

        # Kolla efter meta tags
        meta_tags = soup.find_all("meta")
        if len(meta_tags) > 5:
            score += 0.2

        # Kolla efter structured data
        if soup.find_all(attrs={"itemtype": True}):
            score += 0.1

        return min(score, 1.0)

    async def _generate_ai_recommendations(self, soup, url: str) -> List[str]:
        """Genererar AI-rekommendationer"""
        recommendations = []

        # Analysera sidan och ge rekommendationer
        if not soup.find("title"):
            recommendations.append("L√§gg till en title-tag f√∂r b√§ttre SEO")

        if not soup.find("h1"):
            recommendations.append("L√§gg till en H1-rubrik f√∂r b√§ttre struktur")

        if len(soup.find_all("img")) > 0:
            images_without_alt = [img for img in soup.find_all("img") if not img.get("alt")]
            if images_without_alt:
                recommendations.append(f"L√§gg till alt-text f√∂r {len(images_without_alt)} bilder")

        if len(soup.find_all("a")) > 0:
            links_without_text = [a for a in soup.find_all("a") if not a.get_text().strip()]
            if links_without_text:
                recommendations.append(f"L√§gg till beskrivande text f√∂r {len(links_without_text)} l√§nkar")

        # AI-powered insights
        if self.ai_mode == AIScrapingMode.LEARNING:
            recommendations.append("AI-l√§rande aktiverat - samlar in data f√∂r f√∂rb√§ttringar")

        return recommendations

    def _calculate_confidence_score(self, analysis: Dict[str, Any]) -> float:
        """Ber√§knar confidence score f√∂r AI-analysen"""
        score = 0.0

        # Baserat p√• content insights
        if analysis.get("content_insights"):
            insights = analysis["content_insights"]
            if insights.get("title"):
                score += 0.2
            if insights.get("structure_score", 0) > 0.5:
                score += 0.3
            if insights.get("headings"):
                score += 0.2

        # Baserat p√• selectors
        if analysis.get("selectors_generated"):
            score += 0.3

        return min(score, 1.0)

    def _update_ai_metrics(self, status: int, response_time: float, ai_analysis: Dict[str, Any]):
        """Uppdaterar AI metrics"""
        self.request_count += 1
        self.success_count += 1

        # Uppdatera AI success rate
        if ai_analysis.get("confidence_score", 0) > 0.7:
            self.ai_success_rate = (self.ai_success_rate * 0.9) + 0.1

        # Uppdatera selector accuracy
        if ai_analysis.get("selectors_generated"):
            self.selector_accuracy = (self.selector_accuracy * 0.9) + 0.1

        # L√§gg till learning data
        if self.ai_mode == AIScrapingMode.LEARNING:
            self.learning_data.append(
                {
                    "url": ai_analysis.get("url", ""),
                    "confidence_score": ai_analysis.get("confidence_score", 0),
                    "timestamp": datetime.now().isoformat(),
                    "analysis": ai_analysis,
                }
            )

            # Uppdatera learning progress
            self.learning_progress = min(len(self.learning_data) / 100, 1.0)

        # Generera AI insights
        self._generate_intelligent_insights(ai_analysis)

    def _generate_intelligent_insights(self, ai_analysis: Dict[str, Any]):
        """Genererar intelligenta insights"""
        insights = []

        confidence = ai_analysis.get("confidence_score", 0)
        if confidence > 0.8:
            insights.append("H√∂g konfidens - AI-analysen √§r mycket tillf√∂rlitlig")
        elif confidence > 0.6:
            insights.append("Medelh√∂g konfidens - AI-analysen √§r tillf√∂rlitlig")
        else:
            insights.append("L√•g konfidens - AI-analysen beh√∂ver f√∂rb√§ttringar")

        recommendations = ai_analysis.get("recommendations", [])
        if recommendations:
            insights.append(f"AI rekommenderar {len(recommendations)} f√∂rb√§ttringar")

        # Pattern recognition
        if len(self.learning_data) > 10:
            avg_confidence = sum(d["confidence_score"] for d in self.learning_data[-10:]) / 10
            if avg_confidence > 0.7:
                insights.append("Positiv trend - AI-prestanda f√∂rb√§ttras")
            elif avg_confidence < 0.4:
                insights.append("Negativ trend - AI beh√∂ver justeringar")

        self.intelligent_insights = insights[-5:]  # Beh√•ll senaste 5 insights

    def set_ai_mode(self, mode: AIScrapingMode):
        """S√§tter AI-l√§ge"""
        self.ai_mode = mode

    def get_ai_metrics(self) -> Dict[str, Any]:
        """Returnerar AI metrics"""
        total_requests = max(self.request_count, 1)
        success_rate = min((self.success_count / total_requests) * 100, 100.0)

        return {
            # Grundl√§ggande metrics
            "requests_total": self.request_count,
            "requests_success": self.success_count,
            "requests_error": self.error_count,
            "success_rate": success_rate,
            "uptime_seconds": time.time() - self.start_time,
            "current_rate": random.randint(10, 50),
            "active_sessions": 1,
            "is_running": self.is_running,
            "requests_per_minute": random.randint(10, 50),
            # AI metrics
            "ai_mode": self.ai_mode.value,
            "ai_success_rate": round(self.ai_success_rate * 100, 1),
            "selector_accuracy": round(self.selector_accuracy * 100, 1),
            "learning_progress": round(self.learning_progress * 100, 1),
            "confidence_score": round(self._calculate_overall_confidence(), 1),
            # AI insights
            "intelligent_insights": self.intelligent_insights,
            "ai_recommendations": self._get_ai_recommendations(),
            "learning_data_count": len(self.learning_data),
            "auto_selectors_count": len(self.auto_selectors),
            # Smart analytics
            "pattern_recognition": self.pattern_recognition,
            "anomaly_detection_count": len(self.anomaly_detection),
            "predictive_analytics": self.predictive_analytics,
        }

    def _calculate_overall_confidence(self) -> float:
        """Ber√§knar overall confidence score"""
        if not self.learning_data:
            return 0.0

        recent_data = self.learning_data[-10:]  # Senaste 10 analyser
        avg_confidence = sum(d["confidence_score"] for d in recent_data) / len(recent_data)
        return avg_confidence * 100

    def _get_ai_recommendations(self) -> List[str]:
        """H√§mtar AI-rekommendationer"""
        recommendations = []

        if self.ai_success_rate < 0.7:
            recommendations.append("√ñverv√§g att justera AI-parametrar f√∂r b√§ttre prestanda")

        if self.selector_accuracy < 0.6:
            recommendations.append("Tr√§na AI med fler exempel f√∂r b√§ttre selector-generering")

        if self.learning_progress < 0.5:
            recommendations.append("Forts√§tt samla in learning data f√∂r AI-f√∂rb√§ttringar")

        if not recommendations:
            recommendations.append("AI fungerar optimalt - inga justeringar beh√∂vs")

        return recommendations


class MockProxyManager:
    """Mock proxy manager"""

    def __init__(self):
        self.total_proxies = 10
        self.active_proxies = 8
        self.failed_proxies = 2

    def get_stats(self) -> Dict[str, Any]:
        success_rate = min((self.active_proxies / self.total_proxies) * 100, 100.0)
        return {
            "total_proxies": self.total_proxies,
            "active_proxies": self.active_proxies,
            "failed_proxies": self.failed_proxies,
            "success_rate": success_rate,
            "average_response_time": random.uniform(0.5, 2.0),
            "requests_per_proxy": random.randint(50, 200),
        }


class MockWebhookManager:
    """Mock webhook manager"""

    def __init__(self):
        self.total_webhooks = 5
        self.active_webhooks = 4
        self.sent_events = 150
        self.failed_events = 2

    def get_stats(self) -> Dict[str, Any]:
        total_events = max(self.sent_events + self.failed_events, 1)
        success_rate = min((self.sent_events / total_events) * 100, 100.0)
        return {
            "total_webhooks": self.total_webhooks,
            "active_webhooks": self.active_webhooks,
            "sent_events": self.sent_events,
            "failed_events": self.failed_events,
            "success_rate": success_rate,
            "last_event_time": time.time() - random.randint(0, 300),
        }


class AIDashboardDemo:
    """AI dashboard demo med intelligent features"""

    def __init__(self):
        self.config = Config()
        self.logger = ScrapingLogger(__name__)

        # Skapa AI scraper
        self.scraper = IntelligentScraper()
        self.proxy_manager = MockProxyManager()
        self.webhook_manager = MockWebhookManager()

        # Dashboard med AI features
        self.dashboard = DashboardApp(self.config)
        self.dashboard.set_components(
            scraper=self.scraper,
            proxy_manager=self.proxy_manager,
            webhook_manager=self.webhook_manager,
        )

    async def start(self):
        """Startar AI dashboard demo"""
        self.logger.info("ü§ñ Starting AI Dashboard Demo")

        # Starta AI scraper
        await self.scraper.start()

        # Starta AI scraping i bakgrunden
        scraping_thread = threading.Thread(target=self._run_ai_scraping)
        scraping_thread.daemon = True
        scraping_thread.start()

        # Starta dashboard p√• port 8084
        self.logger.info("üåê Starting AI Dashboard on http://127.0.0.1:8084")

        dashboard_thread = threading.Thread(target=self._run_dashboard)
        dashboard_thread.daemon = True
        dashboard_thread.start()

        await asyncio.sleep(3)

        self.logger.info("‚úÖ AI Dashboard Demo started successfully!")
        self.logger.info("ü§ñ Open http://127.0.0.1:8084 to see AI-powered features")

    def _run_ai_scraping(self):
        """K√∂r AI scraping i bakgrunden"""
        urls = [
            "https://httpbin.org/html",
            "https://httpbin.org/json",
            "https://httpbin.org/xml",
            "https://httpbin.org/headers",
            "https://httpbin.org/user-agent",
        ]

        while self.scraper.is_running:
            try:
                # V√§lj slumpm√§ssig URL
                url = random.choice(urls)

                # Simulera AI scraping
                asyncio.run(self.scraper.scrape_with_ai(url, "product information"))

                time.sleep(random.uniform(2, 5))

            except Exception as e:
                self.logger.error(f"Error in AI scraping: {str(e)}")
                time.sleep(5)

    def _run_dashboard(self):
        """K√∂r dashboard p√• port 8084"""
        try:
            self.dashboard.run(host="127.0.0.1", port=8084)
        except Exception as e:
            self.logger.error(f"Dashboard error: {str(e)}")


async def main():
    """Huvudfunktion"""
    demo = AIDashboardDemo()
    await demo.start()

    # H√•ll ig√•ng
    try:
        while True:
            await asyncio.sleep(1)
    except KeyboardInterrupt:
        await demo.scraper.stop()
        print("\nüëã AI Dashboard Demo stopped")


if __name__ == "__main__":
    asyncio.run(main())
